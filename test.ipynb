{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "konlpy                             0.5.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list | grep konl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard                        2.5.0\n",
      "tensorboard-data-server            0.6.1\n",
      "tensorboard-plugin-wit             1.7.0\n",
      "tensorflow                         2.5.0\n",
      "tensorflow-estimator               2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list | grep tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jpype\n",
    "import json\n",
    "from konlpy.tag import Kkma\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('/Users/asaid/Dev/Udong/Udong_1DCNN_per50/Udong_1DCNN_UPGRADEV3_per50.h5')\n",
    "noun_kkm = ['NNP', 'NNG', 'OL', 'NP','VV', 'VA' ] #사용할 품사\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "with open('/Users/asaid/Dev/Udong/Udong_1DCNN_per50/Udong1DCNN_wordindex_UPGRADEV3.json') as json_file:\n",
    "  word_index = json.load(json_file)\n",
    "  tokenizer.word_index = word_index\n",
    "\n",
    "\n",
    "def tokenizer_kkma_noun2(doc):\n",
    "  jpype.attachThreadToJVM()\n",
    "  token_doc = [ word[0] for word in kkma.pos(doc) if word[1] in noun_kkm ]\n",
    "  return token_doc\n",
    "kkma = Kkma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asaid/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: jpype._core.attachThreadToJVM is deprecated, use java.lang.Thread.attach instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 항목당 확률 악플(0), 공격적(1), 일반(2) : [[0.9309536  0.04195646 0.02708987]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "test = \"찌질이 루저야 꼴값떨지마\"\n",
    "test = tokenizer_kkma_noun2(test)\n",
    "test = tokenizer.texts_to_sequences([test])\n",
    "test = pad_sequences(test, maxlen=13)\n",
    "result = model.predict(test)\n",
    "print('각 항목당 확률 악플(0), 공격적(1), 일반(2) :', result)\n",
    "a = list(result[0])\n",
    "print(a.index(max(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
